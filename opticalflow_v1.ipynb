{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "a34a4a50",
      "metadata": {
        "id": "a34a4a50"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ 라이브러리가 준비되었습니다.\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from IPython.display import HTML, display\n",
        "import base64\n",
        "\n",
        "print(\"✅ 라이브러리가 준비되었습니다.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "0acc105f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "id": "0acc105f",
        "outputId": "0a20d5b3-bd90-4294-ba94-472c4baf53d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Firebase 앱이 이미 초기화되어 있습니다.\n",
            "Storage 버킷에 접근 성공: fairplayfairy-3e2eb.firebasestorage.app\n"
          ]
        }
      ],
      "source": [
        "import firebase_admin\n",
        "from firebase_admin import credentials, storage\n",
        "\n",
        "cred = credentials.Certificate(\"./serviceAccountKey.json\")\n",
        "\n",
        "if not firebase_admin._apps:\n",
        "    firebase_admin.initialize_app(cred, {\n",
        "        'storageBucket': 'fairplayfairy-3e2eb.firebasestorage.app'\n",
        "    })\n",
        "    print(\"Firebase 앱이 성공적으로 초기화되었습니다.\")\n",
        "else:\n",
        "    print(\"Firebase 앱이 이미 초기화되어 있습니다.\")\n",
        "\n",
        "# Storage 버킷 객체 가져오기 예시\n",
        "bucket = storage.bucket()\n",
        "print(\"Storage 버킷에 접근 성공:\", bucket.name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "5e6df206",
      "metadata": {
        "id": "5e6df206"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import traceback\n",
        "\n",
        "def track_aim_in_video(input_path, output_path=None, warmup_frames=0):\n",
        "    \"\"\"\n",
        "    스킵(3초) 로직 제거. WebM 메타 부정확 시에도 전체 프레임 처리.\n",
        "    warmup_frames: 앞 부분은 계산만 하고 aim_movements에 미저장.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        cap = cv2.VideoCapture(input_path)\n",
        "        if not cap.isOpened():\n",
        "            print(f\"Error: 영상을 열 수 없습니다. 경로: {input_path}\")\n",
        "            return None\n",
        "\n",
        "        width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "        fps    = cap.get(cv2.CAP_PROP_FPS)\n",
        "        try:\n",
        "            total_frames_raw = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
        "            total_frames = int(total_frames_raw)\n",
        "            if total_frames <= 0:\n",
        "                total_frames = None\n",
        "        except:\n",
        "            total_frames = None\n",
        "\n",
        "        if width == 0 or height == 0:\n",
        "            print(\"Warning: 해상도 정보 실패\")\n",
        "            cap.release()\n",
        "            return None\n",
        "\n",
        "        # 첫 프레임 읽기\n",
        "        ret, prev_frame = cap.read()\n",
        "        if not ret:\n",
        "            print(\"Error: 첫 프레임 읽기 실패\")\n",
        "            cap.release()\n",
        "            return None\n",
        "\n",
        "        roi_x, roi_y = int(width * 0.2), int(height * 0.2)\n",
        "        roi_w, roi_h = int(width * 0.6), int(height * 0.6)\n",
        "        prev_gray = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
        "        prev_roi  = prev_gray[roi_y:roi_y+roi_h, roi_x:roi_x+roi_w]\n",
        "\n",
        "        aim_movements = []\n",
        "        out = None\n",
        "        if output_path:\n",
        "            use_fps = fps if 1 <= fps <= 480 else 60\n",
        "            fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "            out = cv2.VideoWriter(output_path, fourcc, int(use_fps), (width, height))\n",
        "\n",
        "        frame_index = 0\n",
        "        while True:\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "            roi  = gray[roi_y:roi_y+roi_h, roi_x:roi_x+roi_w]\n",
        "\n",
        "            flow = cv2.calcOpticalFlowFarneback(\n",
        "                prev_roi, roi, None,\n",
        "                0.5, 3, 15, 3, 5, 1.2, 0\n",
        "            )\n",
        "            dx = float(np.mean(flow[...,0]))\n",
        "            dy = float(np.mean(flow[...,1]))\n",
        "            aim_dx, aim_dy = -dx, -dy\n",
        "\n",
        "            if frame_index >= warmup_frames:\n",
        "                aim_movements.append((aim_dx, aim_dy))\n",
        "\n",
        "            if out:\n",
        "                out.write(frame)\n",
        "\n",
        "            prev_roi = roi\n",
        "            frame_index += 1\n",
        "\n",
        "        cap.release()\n",
        "        if out:\n",
        "            out.release()\n",
        "        return aim_movements\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ track_aim_in_video 함수 예외: {e}\")\n",
        "        traceback.print_exc()\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "98eca609",
      "metadata": {
        "id": "98eca609"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0/273] 처리 중: videos/01701665-2d22-4a6c-99e0-f36fa91395cf.webm\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     15\u001b[39m os.close(fd)\n\u001b[32m     16\u001b[39m video_blob.download_to_filename(temp_path)  \u001b[38;5;66;03m# 영상 다운로드 추가\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m aim_data = \u001b[43mtrack_aim_in_video\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtemp_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m all_aim_data.append(aim_data)\n\u001b[32m     19\u001b[39m os.remove(temp_path)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 59\u001b[39m, in \u001b[36mtrack_aim_in_video\u001b[39m\u001b[34m(input_path, output_path, warmup_frames)\u001b[39m\n\u001b[32m     56\u001b[39m gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n\u001b[32m     57\u001b[39m roi  = gray[roi_y:roi_y+roi_h, roi_x:roi_x+roi_w]\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m flow = \u001b[43mcv2\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcalcOpticalFlowFarneback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     60\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprev_roi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mroi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     61\u001b[39m \u001b[43m    \u001b[49m\u001b[32;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m15\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\n\u001b[32m     62\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     63\u001b[39m dx = \u001b[38;5;28mfloat\u001b[39m(np.mean(flow[...,\u001b[32m0\u001b[39m]))\n\u001b[32m     64\u001b[39m dy = \u001b[38;5;28mfloat\u001b[39m(np.mean(flow[...,\u001b[32m1\u001b[39m]))\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "import tempfile\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 영상 리스트 가져오기\n",
        "videos = list(bucket.list_blobs(prefix='videos/'))\n",
        "webm_files = [video for video in videos if video.name.endswith('.webm')]\n",
        "\n",
        "all_videos = webm_files\n",
        "all_aim_data = []\n",
        "\n",
        "# 병렬 처리 없이 순차적으로 전체 영상 처리\n",
        "for i, video_blob in enumerate(all_videos):\n",
        "    print(f\"[{i+1}/{len(all_videos)}] 처리 중: {video_blob.name}\")\n",
        "    fd, temp_path = tempfile.mkstemp(suffix=\".webm\")\n",
        "    os.close(fd)\n",
        "    try:\n",
        "        video_blob.download_to_filename(temp_path)  # 영상 다운로드\n",
        "        aim_data = track_aim_in_video(temp_path, output_path=None)\n",
        "        all_aim_data.append(aim_data)\n",
        "    except Exception as e:\n",
        "        print(f\"영상 처리 중 오류 발생: {e}\")\n",
        "    finally:\n",
        "        if os.path.exists(temp_path):\n",
        "            os.remove(temp_path)\n",
        "\n",
        "print(f\"{len(all_aim_data)}개의 데이터 수집 완료.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85f39a70",
      "metadata": {
        "id": "85f39a70"
      },
      "outputs": [],
      "source": [
        "if not all_aim_data:\n",
        "    print(\"분석 데이터 없음.\")\n",
        "else:\n",
        "    # per-video metric(평균)과 velocity 시퀀스 수집\n",
        "    vel_seqs = []\n",
        "    per_video_stats = {'vel_mean': [], 'acc_mean': [], 'jerk_mean': [], 'anglechg_mean': []}\n",
        "\n",
        "    for item in all_aim_data:\n",
        "        moves = item['data']  # shape (T,2)\n",
        "        vel = np.linalg.norm(moves, axis=1)\n",
        "        acc = np.linalg.norm(np.diff(moves, axis=0), axis=1) if len(moves) > 1 else np.array([0.0])\n",
        "        jerk = np.linalg.norm(np.diff(moves, n=2, axis=0), axis=1) if len(moves) > 2 else np.array([0.0])\n",
        "        ang = np.arctan2(moves[:,1], moves[:,0]) * 180/np.pi\n",
        "        angchg = np.abs(((np.diff(ang) + 180) % 360) - 180) if len(ang) > 1 else np.array([0.0])\n",
        "\n",
        "        per_video_stats['vel_mean'].append(np.mean(vel))\n",
        "        per_video_stats['acc_mean'].append(np.mean(acc))\n",
        "        per_video_stats['jerk_mean'].append(np.mean(jerk))\n",
        "        per_video_stats['anglechg_mean'].append(np.mean(angchg))\n",
        "\n",
        "        vel_seqs.append(vel)\n",
        "\n",
        "    # 시간 길이 맞추기 (짧은 시퀀스는 마지막 값으로 패딩)\n",
        "    max_len = max(len(s) for s in vel_seqs)\n",
        "    padded = np.zeros((len(vel_seqs), max_len))\n",
        "    for idx, seq in enumerate(vel_seqs):\n",
        "        padded[idx, :len(seq)] = seq\n",
        "        if len(seq) < max_len:\n",
        "            padded[idx, len(seq):] = seq[-1]\n",
        "\n",
        "    mean_ts = np.mean(padded, axis=0)\n",
        "    median_ts = np.median(padded, axis=0)\n",
        "\n",
        "    # 1) per-video metric boxplot\n",
        "    plt.figure(figsize=(9,4))\n",
        "    plt.boxplot([per_video_stats['vel_mean'],\n",
        "                 per_video_stats['acc_mean'],\n",
        "                 per_video_stats['jerk_mean'],\n",
        "                 per_video_stats['anglechg_mean']],\n",
        "                labels=['Velocity','Acceleration','Jerk','AngleChange'])\n",
        "    plt.title(f'Per-video metric distributions (n={len(per_video_stats[\"vel_mean\"])})')\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "    # 2) 평균 시간축 시계열\n",
        "    plt.figure(figsize=(12,4))\n",
        "    plt.plot(mean_ts, label='Mean Velocity', color='b')\n",
        "    plt.plot(median_ts, label='Median Velocity', color='g')\n",
        "    plt.xlabel('Frame')\n",
        "    plt.ylabel('Velocity (pixels/frame)')\n",
        "    plt.title('Mean/Median Velocity Time Series (across samples)')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "    # 3) 요약 통계 출력\n",
        "    for k, vals in per_video_stats.items():\n",
        "        print(f\"{k}: mean={np.mean(vals):.3f}, std={np.std(vals):.3f}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
