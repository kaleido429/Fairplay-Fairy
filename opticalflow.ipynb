{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34a4a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from IPython.display import HTML, display\n",
    "import base64\n",
    "\n",
    "print(\"✅ 라이브러리가 준비되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acc105f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import firebase_admin\n",
    "from firebase_admin import credentials, storage\n",
    "\n",
    "cred = credentials.Certificate(\"./serviceAccountKey.json\")\n",
    "\n",
    "if not firebase_admin._apps:\n",
    "    firebase_admin.initialize_app(cred, {\n",
    "        'storageBucket': 'fairplayfairy-3e2eb.firebasestorage.app'\n",
    "    })\n",
    "    print(\"Firebase 앱이 성공적으로 초기화되었습니다.\")\n",
    "else:\n",
    "    print(\"Firebase 앱이 이미 초기화되어 있습니다.\")\n",
    "\n",
    "# Storage 버킷 객체 가져오기 예시\n",
    "bucket = storage.bucket()\n",
    "print(\"Storage 버킷에 접근 성공:\", bucket.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6df206",
   "metadata": {},
   "outputs": [],
   "source": [
    "def track_aim_in_video(input_path, output_path=\"result_local.mp4\"):\n",
    "    \"\"\"\n",
    "    영상 파일을 입력받아 옵티컬 플로우로 에임을 추적하고,\n",
    "    결과 영상 저장 및 에임 이동 데이터를 반환합니다.\n",
    "    output_path가 None이면 결과 영상을 저장하지 않습니다.\n",
    "    \"\"\"\n",
    "    aim_movements = []\n",
    "    try:\n",
    "        cap = cv2.VideoCapture(input_path)\n",
    "        if not cap.isOpened():\n",
    "            print(\"Error: 영상을 열 수 없습니다.\")\n",
    "            return None\n",
    "\n",
    "        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "        \n",
    "        out = None\n",
    "        if output_path is not None:\n",
    "            fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "            out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "        \n",
    "        ret, prev_frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Error: 첫 프레임을 읽을 수 없습니다.\")\n",
    "            cap.release()\n",
    "            if out is not None:\n",
    "                out.release()\n",
    "            return None\n",
    "            \n",
    "        roi_x, roi_y = int(width * 0.2), int(height * 0.2)\n",
    "        roi_w, roi_h = int(width * 0.6), int(height * 0.6)\n",
    "\n",
    "        prev_gray = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
    "        prev_roi = prev_gray[roi_y:roi_y+roi_h, roi_x:roi_x+roi_w]\n",
    "\n",
    "        frame_count = 0\n",
    "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        \n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            frame_count += 1\n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            roi = gray[roi_y:roi_y+roi_h, roi_x:roi_x+roi_w]\n",
    "\n",
    "            flow = cv2.calcOpticalFlowFarneback(prev_roi, roi, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "            \n",
    "            dx, dy = np.mean(flow[..., 0]), np.mean(flow[..., 1])\n",
    "            \n",
    "            aim_dx, aim_dy = -dx, -dy\n",
    "            aim_movements.append((aim_dx, aim_dy)) # 에임 이동 데이터 저장\n",
    "            \n",
    "            aim_speed = np.sqrt(aim_dx**2 + aim_dy**2)\n",
    "            \n",
    "            if aim_speed > 1.0:\n",
    "                center_x, center_y = width // 2, height // 2\n",
    "                arrow_end_x = int(center_x + aim_dx * 20)\n",
    "                arrow_end_y = int(center_y + aim_dy * 20)\n",
    "                \n",
    "                cv2.arrowedLine(frame, (center_x, center_y), (arrow_end_x, arrow_end_y),\n",
    "                                (0, 255, 255), 3, tipLength=0.3)\n",
    "            \n",
    "            if out is not None:\n",
    "                out.write(frame)\n",
    "            prev_roi = roi\n",
    "            \n",
    "            if frame_count % 30 == 0:\n",
    "                print(f\"진행률: {frame_count} / {total_frames} 프레임 처리 중...\")\n",
    "\n",
    "        if output_path is not None:\n",
    "            print(f\"✅ 영상 처리가 완료되었습니다. 결과가 '{output_path}'에 저장되었습니다.\")\n",
    "        else:\n",
    "            print(f\"✅ 영상 처리가 완료되었습니다. (결과 영상 저장 안함)\")\n",
    "\n",
    "        cap.release()\n",
    "        if out is not None:\n",
    "            out.release()\n",
    "        return aim_movements\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"오류가 발생했습니다: {e}\")\n",
    "        return None\n",
    "\n",
    "# --- 실행 ---\n",
    "aim_data = None\n",
    "if 'input_filename' in locals() and os.path.exists(input_filename):\n",
    "    output_filename = \"result_local.mp4\"\n",
    "    aim_data = track_aim_in_video(input_filename, output_filename)\n",
    "else:\n",
    "    print(\"⚠️ 파일 경로를 먼저 확인해주세요.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98eca609",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import tempfile\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "videos = list(bucket.list_blobs(prefix='videos/'))\n",
    "webm_files = [video for video in videos if video.name.endswith('.webm')]\n",
    "\n",
    "random_videos = random.sample(webm_files, 10) #10개 랜덤 선택\n",
    "\n",
    "all_aim_data = []\n",
    "\n",
    "# 10개의 샘플데이터 optical flow 추출(영상저장 X, 시각화 X)\n",
    "for i, video_blob in enumerate(random_videos):\n",
    "    print(f\"[{i}/{len(random_videos)}] 처리 중: {video_blob.name}\")\n",
    "    fd, temp_path = tempfile.mkstemp(suffix=\".webm\")\n",
    "    aim_data = track_aim_in_video(temp_path, output_path=None)\n",
    "    all_aim_data.append(aim_data)\n",
    "    os.close(fd)\n",
    "    os.remove(temp_path)\n",
    "\n",
    "print(f\"{len(all_aim_data)}개의 데이터 수집 완료.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f39a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not all_aim_data:\n",
    "    print(\"분석 데이터 없음.\")\n",
    "else:\n",
    "    # per-video metric(평균)과 velocity 시퀀스 수집\n",
    "    vel_seqs = []\n",
    "    per_video_stats = {'vel_mean': [], 'acc_mean': [], 'jerk_mean': [], 'anglechg_mean': []}\n",
    "\n",
    "    for item in all_aim_data:\n",
    "        moves = item['data']  # shape (T,2)\n",
    "        vel = np.linalg.norm(moves, axis=1)\n",
    "        acc = np.linalg.norm(np.diff(moves, axis=0), axis=1) if len(moves) > 1 else np.array([0.0])\n",
    "        jerk = np.linalg.norm(np.diff(moves, n=2, axis=0), axis=1) if len(moves) > 2 else np.array([0.0])\n",
    "        ang = np.arctan2(moves[:,1], moves[:,0]) * 180/np.pi\n",
    "        angchg = np.abs(((np.diff(ang) + 180) % 360) - 180) if len(ang) > 1 else np.array([0.0])\n",
    "\n",
    "        per_video_stats['vel_mean'].append(np.mean(vel))\n",
    "        per_video_stats['acc_mean'].append(np.mean(acc))\n",
    "        per_video_stats['jerk_mean'].append(np.mean(jerk))\n",
    "        per_video_stats['anglechg_mean'].append(np.mean(angchg))\n",
    "\n",
    "        vel_seqs.append(vel)\n",
    "\n",
    "    # 시간 길이 맞추기 (짧은 시퀀스는 마지막 값으로 패딩)\n",
    "    max_len = max(len(s) for s in vel_seqs)\n",
    "    padded = np.zeros((len(vel_seqs), max_len))\n",
    "    for idx, seq in enumerate(vel_seqs):\n",
    "        padded[idx, :len(seq)] = seq\n",
    "        if len(seq) < max_len:\n",
    "            padded[idx, len(seq):] = seq[-1]\n",
    "\n",
    "    mean_ts = np.mean(padded, axis=0)\n",
    "    median_ts = np.median(padded, axis=0)\n",
    "\n",
    "    # 1) per-video metric boxplot\n",
    "    plt.figure(figsize=(9,4))\n",
    "    plt.boxplot([per_video_stats['vel_mean'],\n",
    "                 per_video_stats['acc_mean'],\n",
    "                 per_video_stats['jerk_mean'],\n",
    "                 per_video_stats['anglechg_mean']],\n",
    "                labels=['Velocity','Acceleration','Jerk','AngleChange'])\n",
    "    plt.title(f'Per-video metric distributions (n={len(per_video_stats[\"vel_mean\"])})')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    # 2) 평균 시간축 시계열\n",
    "    plt.figure(figsize=(12,4))\n",
    "    plt.plot(mean_ts, label='Mean Velocity', color='b')\n",
    "    plt.plot(median_ts, label='Median Velocity', color='g')\n",
    "    plt.xlabel('Frame')\n",
    "    plt.ylabel('Velocity (pixels/frame)')\n",
    "    plt.title('Mean/Median Velocity Time Series (across samples)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    # 3) 요약 통계 출력\n",
    "    for k, vals in per_video_stats.items():\n",
    "        print(f\"{k}: mean={np.mean(vals):.3f}, std={np.std(vals):.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
